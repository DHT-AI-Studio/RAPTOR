# Inference æ¨¡çµ„é…ç½®æ›´æ–°ç¸½çµ

## ğŸ“Š æ›´æ–°å…§å®¹

### 1. Ollama æ¨¡å‹åç¨±æ˜ å°„ä¿®å¾© âœ…
- **å•é¡Œ**: MLflow è¨»å†Šåç¨±èˆ‡æœ¬åœ° Ollama åç¨±ä¸åŒå°è‡´æ¨ç†å¤±æ•—
- **ä¿®å¾©**: Router å±¤æ·»åŠ  Executor ç·©å­˜æ©Ÿåˆ¶
- **æ–‡æª”**: [OLLAMA_FIX_SUMMARY.md](./OLLAMA_FIX_SUMMARY.md)

### 2. ä»»å‹™é¡å‹ç´°åˆ†ï¼ˆèˆ‡ Core é…ç½®å°é½Šï¼‰âœ…
- **è®Šæ›´**: æ”¯æŒ `text-generation-ollama`, `text-generation-hf` ç­‰ç´°åˆ†ä»»å‹™
- **å‘ä¸‹å…¼å®¹**: ä¿ç•™é€šç”¨ä»»å‹™é¡å‹ï¼ˆå¦‚ `text-generation`ï¼‰
- **æ–‡æª”**: [INFERENCE_TASK_TYPES.md](./INFERENCE_TASK_TYPES.md)

## ğŸ¯ æ ¸å¿ƒæ”¹é€²

### ä»»å‹™é¡å‹æ˜ å°„

| åŸä»»å‹™é¡å‹ | æ–°ä»»å‹™é¡å‹ | å¼•æ“ | ç‹€æ…‹ |
|-----------|-----------|------|------|
| `text-generation` | `text-generation-ollama` | ollama | â­ æ¨è–¦ |
| `text-generation` | `text-generation-hf` | transformers | â­ æ¨è–¦ |
| `text-generation` | `text-generation` | both | âœ… å…¼å®¹ |
| `asr` | `asr-hf` | transformers | â­ æ¨è–¦ |
| `asr` | `asr` | transformers | âœ… å…¼å®¹ |
| `ocr` | `ocr-hf` | transformers | â­ æ¨è–¦ |
| `ocr` | `ocr` | transformers | âœ… å…¼å®¹ |
| - | `vad-hf` | transformers | ğŸ†• æ–°å¢ |
| - | `scene-detection` | transformers | ğŸ†• æ–°å¢ |
| - | `image-captioning` | transformers | ğŸ†• æ–°å¢ |
| - | `video-summary` | transformers | ğŸ†• æ–°å¢ |
| - | `audio-transcription` | transformers | ğŸ†• æ–°å¢ |

## ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶

### æ ¸å¿ƒä¿®å¾©
1. **src/inference/router.py** â­
   - æ·»åŠ  `_executors` ç·©å­˜å­—å…¸
   - æ”¯æŒç´°åˆ†ä»»å‹™é¡å‹
   - æ›´æ–°ä»»å‹™æè¿°

2. **src/inference/manager.py** â­
   - æ›´æ–°åƒæ•¸é©—è­‰é‚è¼¯
   - æ“´å±•æ”¯æŒçš„ä»»å‹™åˆ—è¡¨
   - æ›´æ–° `get_supported_tasks()` æ–¹æ³•

3. **src/api/inference_api.py**
   - æ›´æ–° API æ–‡æª”å­—ç¬¦ä¸²
   - åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„ä»»å‹™é¡å‹

### æ–‡æª”
4. **docs/OLLAMA_FIX_SUMMARY.md** ğŸ†•
   - Ollama å•é¡Œåˆ†æå’Œä¿®å¾©ç¸½çµ
   
5. **docs/OLLAMA_MLFLOW_MAPPING_FIX.md** ğŸ†•
   - æŠ€è¡“ç´°ç¯€å’Œå¯¦ç¾æµç¨‹
   
6. **docs/OLLAMA_MLFLOW_QUICKSTART.md** ğŸ†•
   - MLflow æ¨¡å‹è¨»å†Šå¿«é€ŸæŒ‡å—
   
7. **docs/OLLAMA_FIX_README.md** ğŸ†•
   - Ollama ä¿®å¾©å¿«é€Ÿåƒè€ƒ
   
8. **docs/INFERENCE_TASK_TYPES.md** ğŸ†•
   - ä»»å‹™é¡å‹å®Œæ•´é…ç½®èªªæ˜
   
9. **docs/INFERENCE_TASK_QUICK_REF.md** ğŸ†•
   - ä»»å‹™é¡å‹å¿«é€Ÿåƒè€ƒ

### æ¸¬è©¦
10. **test/test_ollama_mlflow_mapping.py** ğŸ†•
    - Ollama MLflow æ˜ å°„æ¸¬è©¦å¥—ä»¶

## ğŸš€ ä½¿ç”¨æŒ‡å—

### æ–¹å¼ 1: ä½¿ç”¨ç´°åˆ†ä»»å‹™é¡å‹ï¼ˆæ¨è–¦ï¼‰

```python
# Ollama æ¨ç†
{
    "task": "text-generation-ollama",
    "engine": "ollama",
    "model_name": "llama2-7b-chat",
    "data": {"inputs": "ä½ å¥½"},
    "options": {"max_length": 100}
}

# HuggingFace æ¨ç†
{
    "task": "text-generation-hf",
    "engine": "transformers",
    "model_name": "gpt2",
    "data": {"inputs": "AI"},
    "options": {"max_length": 50}
}
```

### æ–¹å¼ 2: ä½¿ç”¨é€šç”¨ä»»å‹™é¡å‹ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰

```python
{
    "task": "text-generation",
    "engine": "ollama",  # é€šé engine å€åˆ†
    "model_name": "llama2-7b-chat",
    "data": {"inputs": "ä½ å¥½"},
    "options": {"max_length": 100}
}
```

## âš™ï¸ MLflow é…ç½®è¦æ±‚

### 1. Ollama æ¨¡å‹

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# å¿…é ˆæ·»åŠ å…©å€‹ tags
client.set_model_version_tag(
    name="llama2-7b-chat",
    version="1",
    key="inference_task",
    value="text-generation-ollama"  # å°æ‡‰ä»»å‹™é¡å‹
)

client.set_model_version_tag(
    name="llama2-7b-chat",
    version="1",
    key="ollama_model_name",
    value="llama2:7b"  # æœ¬åœ° Ollama åç¨±
)
```

### 2. HuggingFace æ¨¡å‹

```python
client.set_model_version_tag(
    name="gpt2-chinese",
    version="1",
    key="inference_task",
    value="text-generation-hf"  # å°æ‡‰ä»»å‹™é¡å‹
)
```

## ğŸ“‹ èˆ‡ inference.yaml å°æ‡‰

```yaml
# src/core/configs/inference.yaml
task_to_models:
  text-generation-ollama:
    strategy: "priority"
    discovery:
      source: "mlflow"
      filter: "tags.inference_task = 'text-generation-ollama'"
  
  text-generation-hf:
    strategy: "priority"
    discovery:
      source: "mlflow"
      filter: "tags.inference_task = 'text-generation-hf'"
```

## ğŸ§ª æ¸¬è©¦

```bash
# Ollama æ˜ å°„æ¸¬è©¦
python test/test_ollama_mlflow_mapping.py

# API æ¸¬è©¦
curl -X POST http://localhost:8000/inference/infer \
  -H "Content-Type: application/json" \
  -d '{
    "task": "text-generation-ollama",
    "engine": "ollama",
    "model_name": "llama2-7b-chat",
    "data": {"inputs": "æ¸¬è©¦"},
    "options": {}
  }'

# æŸ¥çœ‹æ”¯æŒçš„ä»»å‹™
curl http://localhost:8000/inference/supported-tasks
```

## âœ… æª¢æŸ¥æ¸…å–®

é…ç½® Ollama æ¨¡å‹æ™‚ï¼š
- [ ] åœ¨ MLflow è¨»å†Šæ¨¡å‹
- [ ] æ·»åŠ  `inference_task` tagï¼ˆå€¼ç‚º `text-generation-ollama`ï¼‰
- [ ] æ·»åŠ  `ollama_model_name` tagï¼ˆå€¼ç‚ºæœ¬åœ° Ollama åç¨±ï¼‰
- [ ] åœ¨ `inference.yaml` ä¸­é…ç½®å°æ‡‰çš„ filter
- [ ] æ¸¬è©¦æ¨ç†åŠŸèƒ½

é…ç½® HuggingFace æ¨¡å‹æ™‚ï¼š
- [ ] åœ¨ MLflow è¨»å†Šæ¨¡å‹
- [ ] æ·»åŠ  `inference_task` tagï¼ˆå€¼ç‚ºå°æ‡‰çš„ä»»å‹™é¡å‹ï¼Œå¦‚ `text-generation-hf`ï¼‰
- [ ] åœ¨ `inference.yaml` ä¸­é…ç½®å°æ‡‰çš„ filter
- [ ] æ¸¬è©¦æ¨ç†åŠŸèƒ½

## ğŸ“š æ–‡æª”å°èˆª

### å¿«é€Ÿé–‹å§‹
- [OLLAMA_FIX_README.md](./OLLAMA_FIX_README.md) - Ollama å¿«é€Ÿåƒè€ƒ
- [INFERENCE_TASK_QUICK_REF.md](./INFERENCE_TASK_QUICK_REF.md) - ä»»å‹™é¡å‹å¿«é€Ÿåƒè€ƒ

### è©³ç´°èªªæ˜
- [OLLAMA_FIX_SUMMARY.md](./OLLAMA_FIX_SUMMARY.md) - Ollama ä¿®å¾©å®Œæ•´èªªæ˜
- [INFERENCE_TASK_TYPES.md](./INFERENCE_TASK_TYPES.md) - ä»»å‹™é¡å‹å®Œæ•´é…ç½®

### æ“ä½œæŒ‡å—
- [OLLAMA_MLFLOW_QUICKSTART.md](./OLLAMA_MLFLOW_QUICKSTART.md) - MLflow è¨»å†ŠæŒ‡å—
- [OLLAMA_MLFLOW_MAPPING_FIX.md](./OLLAMA_MLFLOW_MAPPING_FIX.md) - æŠ€è¡“å¯¦ç¾ç´°ç¯€

## ğŸ”„ ç‰ˆæœ¬ä¿¡æ¯

- **ç‰ˆæœ¬**: v2.1.0
- **æ›´æ–°æ—¥æœŸ**: 2025-10-13
- **ä¸»è¦è®Šæ›´**:
  1. ä¿®å¾© Ollama æ¨¡å‹åç¨±æ˜ å°„å•é¡Œï¼ˆv2.0.1ï¼‰
  2. æ”¯æŒç´°åˆ†ä»»å‹™é¡å‹ï¼Œèˆ‡ Core é…ç½®å°é½Šï¼ˆv2.1.0ï¼‰
- **å‘ä¸‹å…¼å®¹**: æ˜¯ âœ…
- **é‡å¤§è®Šæ›´**: å¦

## âš ï¸ æ³¨æ„äº‹é …

1. **å‘½åè¦å‰‡**
   - `-ollama` å¾Œç¶´ï¼šOllama å¼•æ“å°ˆç”¨
   - `-hf` å¾Œç¶´ï¼šHuggingFace å¼•æ“å°ˆç”¨
   - ç„¡å¾Œç¶´ï¼šé€šç”¨ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰

2. **MLflow Tags**
   - `inference_task`: å¿…é ˆèˆ‡ä»»å‹™é¡å‹åç¨±ä¸€è‡´
   - `ollama_model_name`: Ollama æ¨¡å‹å¿…éœ€

3. **å‘ä¸‹å…¼å®¹**
   - æ‰€æœ‰èˆŠ API èª¿ç”¨ä»ç„¶æœ‰æ•ˆ
   - å»ºè­°æ–°ä»£ç¢¼ä½¿ç”¨ç´°åˆ†ä»»å‹™é¡å‹

4. **æ€§èƒ½å„ªåŒ–**
   - Router å±¤ Executor ç·©å­˜
   - é¿å…é‡è¤‡æŸ¥è©¢ MLflow
   - æ¨¡å‹åç¨±æ˜ å°„æŒä¹…åŒ–

## ğŸ‰ ç¸½çµ

æœ¬æ¬¡æ›´æ–°å¯¦ç¾äº†å…©å€‹ä¸»è¦ç›®æ¨™ï¼š

1. âœ… **ä¿®å¾© Ollama æ¨¡å‹åç¨±æ˜ å°„å•é¡Œ**
   - æ·»åŠ  Router å±¤ Executor ç·©å­˜
   - ç¢ºä¿æ¨¡å‹åç¨±æ˜ å°„æŒä¹…åŒ–
   - æå‡æ¨ç†æ€§èƒ½

2. âœ… **ä»»å‹™é¡å‹èˆ‡ Core é…ç½®å°é½Š**
   - æ”¯æŒç´°åˆ†ä»»å‹™é¡å‹ï¼ˆ`-ollama`, `-hf` å¾Œç¶´ï¼‰
   - ä¿æŒå‘ä¸‹å…¼å®¹æ€§
   - æ“´å±•æ–°ä»»å‹™é¡å‹æ”¯æŒ

ç³»çµ±ç¾åœ¨èƒ½å¤ ï¼š
- æ­£ç¢ºè™•ç† MLflow å’Œæœ¬åœ° Ollama æ¨¡å‹åç¨±æ˜ å°„
- æ”¯æŒèˆ‡ `inference.yaml` ä¸€è‡´çš„ç´°åˆ†ä»»å‹™é¡å‹
- ä¿æŒè‰¯å¥½çš„å‘ä¸‹å…¼å®¹æ€§
- æä¾›æ›´éˆæ´»çš„æ¨ç†é…ç½®é¸é …
