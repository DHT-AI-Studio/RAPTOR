# Ollama æ¨¡å‹ MLflow è¨»å†Šå¿«é€ŸæŒ‡å—

## å•é¡Œå ´æ™¯

ç•¶ä½ åœ¨ MLflow ä¸­è¨»å†Š Ollama æ¨¡å‹æ™‚ï¼Œå¯èƒ½æœƒé‡åˆ°ä»¥ä¸‹æƒ…æ³ï¼š

- **MLflow è¨»å†Šåç¨±**: `llama2-7b-chat` ï¼ˆæ›´å‹å¥½çš„åç¨±ï¼‰
- **æœ¬åœ° Ollama åç¨±**: `llama2:7b` ï¼ˆOllama æœå‹™ä¸­çš„å¯¦éš›åç¨±ï¼‰

å¦‚æœæ²’æœ‰æ­£ç¢ºé…ç½®ï¼ŒAPI æ¨ç†æ™‚æœƒæ‰¾ä¸åˆ°æ¨¡å‹ã€‚

## è§£æ±ºæ–¹æ¡ˆ

### æ­¥é©Ÿ 1: è¨»å†Šæ¨¡å‹æ™‚æ·»åŠ  tag

ä½¿ç”¨ Python è…³æœ¬è¨»å†Šæ¨¡å‹ï¼š

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# æ–¹æ³• 1: è¨»å†Šæ–°æ¨¡å‹ç‰ˆæœ¬æ™‚æ·»åŠ  tag
model_version = client.create_model_version(
    name="llama2-7b-chat",
    source="models:/llama2/1",
    tags={
        "ollama_model_name": "llama2:7b",  # ğŸ‘ˆ é—œéµé…ç½®
        "engine": "ollama",
        "task": "text-generation"
    }
)

# æ–¹æ³• 2: ç‚ºç¾æœ‰æ¨¡å‹ç‰ˆæœ¬æ·»åŠ  tag
client.set_model_version_tag(
    name="llama2-7b-chat",
    version="1",
    key="ollama_model_name",
    value="llama2:7b"  # ğŸ‘ˆ é—œéµé…ç½®
)
```

### æ­¥é©Ÿ 2: é©—è­‰é…ç½®

```python
# æª¢æŸ¥ tag æ˜¯å¦æ­£ç¢ºè¨­ç½®
model_version = client.get_model_version(
    name="llama2-7b-chat",
    version="1"
)

print(f"Tags: {model_version.tags}")
# è¼¸å‡º: {'ollama_model_name': 'llama2:7b', ...}
```

### æ­¥é©Ÿ 3: ä½¿ç”¨ API é€²è¡Œæ¨ç†

```python
import requests

response = requests.post(
    "http://localhost:8000/inference/infer",
    json={
        "task": "text-generation",
        "engine": "ollama",
        "model_name": "llama2-7b-chat",  # ä½¿ç”¨ MLflow è¨»å†Šåç¨±
        "data": {"inputs": "ä½ å¥½"},
        "options": {"max_length": 100}
    }
)

print(response.json())
```

## å®Œæ•´ç¤ºä¾‹è…³æœ¬

```python
#!/usr/bin/env python3
"""
è¨»å†Š Ollama æ¨¡å‹åˆ° MLflow çš„å®Œæ•´ç¤ºä¾‹
"""

import mlflow
from mlflow.tracking import MlflowClient

# é…ç½® MLflow
mlflow.set_tracking_uri("http://localhost:5000")

client = MlflowClient()

# è¦è¨»å†Šçš„æ¨¡å‹åˆ—è¡¨
models_to_register = [
    {
        "mlflow_name": "llama2-7b-chat",
        "ollama_name": "llama2:7b",
        "description": "Llama 2 7B Chat æ¨¡å‹"
    },
    {
        "mlflow_name": "mistral-7b-instruct",
        "ollama_name": "mistral:7b-instruct",
        "description": "Mistral 7B Instruct æ¨¡å‹"
    },
    {
        "mlflow_name": "codellama-13b",
        "ollama_name": "codellama:13b",
        "description": "Code Llama 13B æ¨¡å‹"
    }
]

for model_info in models_to_register:
    try:
        print(f"\nè¨»å†Šæ¨¡å‹: {model_info['mlflow_name']}")
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        try:
            existing_model = client.get_registered_model(model_info['mlflow_name'])
            print(f"  æ¨¡å‹å·²å­˜åœ¨ï¼Œæ·»åŠ æ–°ç‰ˆæœ¬...")
            
            # å‰µå»ºæ–°ç‰ˆæœ¬
            model_version = client.create_model_version(
                name=model_info['mlflow_name'],
                source=f"models:/{model_info['mlflow_name']}/latest",
                description=model_info['description']
            )
            
        except:
            print(f"  å‰µå»ºæ–°æ¨¡å‹...")
            # å‰µå»ºæ–°æ¨¡å‹
            client.create_registered_model(
                name=model_info['mlflow_name'],
                description=model_info['description']
            )
            
            model_version = client.create_model_version(
                name=model_info['mlflow_name'],
                source="none",  # Ollama æ¨¡å‹ä¸éœ€è¦ source
                description=model_info['description']
            )
        
        # æ·»åŠ é—œéµ tag
        client.set_model_version_tag(
            name=model_info['mlflow_name'],
            version=str(model_version.version),
            key="ollama_model_name",
            value=model_info['ollama_name']
        )
        
        # æ·»åŠ å…¶ä»– tags
        tags = {
            "engine": "ollama",
            "task": "text-generation",
            "framework": "ollama"
        }
        
        for key, value in tags.items():
            client.set_model_version_tag(
                name=model_info['mlflow_name'],
                version=str(model_version.version),
                key=key,
                value=value
            )
        
        print(f"âœ… æˆåŠŸè¨»å†Š: {model_info['mlflow_name']} -> {model_info['ollama_name']}")
        
    except Exception as e:
        print(f"âŒ è¨»å†Šå¤±æ•—: {e}")

print("\næ‰€æœ‰æ¨¡å‹è¨»å†Šå®Œæˆï¼")
```

## æª¢æŸ¥ Ollama å¯ç”¨æ¨¡å‹

```bash
# åˆ—å‡ºæœ¬åœ° Ollama æ‰€æœ‰å¯ç”¨æ¨¡å‹
curl http://localhost:11434/api/tags | jq '.models[].name'
```

## å¸¸è¦‹å•é¡Œ

### Q1: å¿˜è¨˜æ·»åŠ  `ollama_model_name` tag æ€éº¼è¾¦ï¼Ÿ

**A**: å¯ä»¥éš¨æ™‚è£œå……ï¼š

```python
client.set_model_version_tag(
    name="your-model-name",
    version="1",
    key="ollama_model_name",
    value="actual-ollama-name"
)
```

### Q2: å¦‚ä½•æ‰¹é‡æ›´æ–°ç¾æœ‰æ¨¡å‹ï¼Ÿ

**A**: ä½¿ç”¨è…³æœ¬æ‰¹é‡è™•ç†ï¼š

```python
# ç²å–æ‰€æœ‰ä½¿ç”¨ Ollama å¼•æ“çš„æ¨¡å‹
all_models = client.search_registered_models()

for model in all_models:
    for version in client.search_model_versions(f"name='{model.name}'"):
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if "engine" in version.tags and version.tags["engine"] == "ollama":
            if "ollama_model_name" not in version.tags:
                # éœ€è¦æ‰‹å‹•æŒ‡å®šæ­£ç¢ºçš„ ollama æ¨¡å‹åç¨±
                ollama_name = input(f"è¼¸å…¥ {model.name} çš„ Ollama æ¨¡å‹åç¨±: ")
                client.set_model_version_tag(
                    name=model.name,
                    version=version.version,
                    key="ollama_model_name",
                    value=ollama_name
                )
```

### Q3: ä¸ä½¿ç”¨ MLflowï¼Œç›´æ¥ç”¨ Ollama åç¨±å¯ä»¥å—ï¼Ÿ

**A**: å¯ä»¥ï¼ç³»çµ±æ”¯æŒå…©ç¨®æ–¹å¼ï¼š

```python
# æ–¹å¼ 1: ä½¿ç”¨ MLflow åç¨±ï¼ˆæ¨è–¦ï¼Œä¾¿æ–¼ç®¡ç†ï¼‰
{
    "model_name": "llama2-7b-chat"
}

# æ–¹å¼ 2: ç›´æ¥ä½¿ç”¨ Ollama åç¨±
{
    "model_name": "llama2:7b"
}
```

## æ¸¬è©¦é©—è­‰

```bash
# é‹è¡Œæ¸¬è©¦è…³æœ¬
cd /opt/home/george/george-test/AiModelLifecycle/VIE01/AiModelLifecycle
python test/test_ollama_mlflow_mapping.py
```

## ç›¸é—œæ–‡æª”

- [OLLAMA_MLFLOW_MAPPING_FIX.md](./OLLAMA_MLFLOW_MAPPING_FIX.md) - æŠ€è¡“ç´°ç¯€å’Œä¿®å¾©èªªæ˜
- [MLflow Models](https://mlflow.org/docs/latest/models.html) - MLflow å®˜æ–¹æ–‡æª”
- [Ollama API](https://github.com/ollama/ollama/blob/main/docs/api.md) - Ollama API æ–‡æª”
