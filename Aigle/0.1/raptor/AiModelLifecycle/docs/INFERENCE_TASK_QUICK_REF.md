# Inference ä»»å‹™é¡å‹å¿«é€Ÿåƒè€ƒ

## ğŸ¯ æ ¸å¿ƒè®Šæ›´

ç‚ºäº†èˆ‡ `src/core/configs/inference.yaml` ä¿æŒä¸€è‡´ï¼Œä»»å‹™é¡å‹ç¾å·²ç´°åˆ†ï¼š

### æ–‡æœ¬ç”Ÿæˆ
- `text-generation-ollama` â†’ Ollama å¼•æ“å°ˆç”¨ â­ æ¨è–¦
- `text-generation-hf` â†’ HuggingFace å¼•æ“å°ˆç”¨ â­ æ¨è–¦
- `text-generation` â†’ é€šç”¨ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰

### èªéŸ³è­˜åˆ¥
- `asr-hf` â†’ HuggingFace å°ˆç”¨ â­ æ¨è–¦
- `asr` â†’ é€šç”¨ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰

### OCR
- `ocr-hf` â†’ HuggingFace å°ˆç”¨ â­ æ¨è–¦
- `ocr` â†’ é€šç”¨ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰

### æ–°å¢ä»»å‹™
- `vad-hf` â†’ èªéŸ³æ´»å‹•æª¢æ¸¬
- `scene-detection` â†’ å ´æ™¯æª¢æ¸¬
- `image-captioning` â†’ åœ–åƒæ¨™é¡Œç”Ÿæˆ
- `video-summary` â†’ è¦–é »æ‘˜è¦
- `audio-transcription` â†’ éŸ³é »è½‰éŒ„

## ğŸ“ ä½¿ç”¨ç¯„ä¾‹

### Ollama æ¨ç†ï¼ˆæ¨è–¦ç”¨æ³•ï¼‰

```python
{
    "task": "text-generation-ollama",  # æ–°ï¼šæ˜ç¢ºæŒ‡å®š
    "engine": "ollama",
    "model_name": "llama2-7b-chat",
    "data": {"inputs": "ä½ å¥½"},
    "options": {"max_length": 100}
}
```

### HuggingFace æ¨ç†ï¼ˆæ¨è–¦ç”¨æ³•ï¼‰

```python
# æ–‡æœ¬ç”Ÿæˆ
{
    "task": "text-generation-hf",  # æ–°ï¼šæ˜ç¢ºæŒ‡å®š
    "engine": "transformers",
    "model_name": "gpt2",
    "data": {"inputs": "äººå·¥æ™ºèƒ½"},
    "options": {"max_length": 50}
}

# èªéŸ³è­˜åˆ¥
{
    "task": "asr-hf",  # æ–°ï¼šæ˜ç¢ºæŒ‡å®š
    "engine": "transformers",
    "model_name": "whisper-large",
    "data": {"audio": "/path/to/audio.wav"},
    "options": {}
}
```

## ğŸ”„ å‘ä¸‹å…¼å®¹

èˆŠçš„ API èª¿ç”¨ä»ç„¶æœ‰æ•ˆï¼š

```python
# ä»ç„¶æ”¯æŒ
{
    "task": "text-generation",  # èˆŠï¼šé€šç”¨é¡å‹
    "engine": "ollama",
    "model_name": "llama2-7b-chat",
    "data": {"inputs": "ä½ å¥½"},
    "options": {"max_length": 100}
}
```

## ğŸ“‹ MLflow é…ç½®æª¢æŸ¥æ¸…å–®

- [ ] æ·»åŠ  `inference_task` tagï¼ˆå¦‚ `text-generation-ollama`ï¼‰
- [ ] Ollama æ¨¡å‹æ·»åŠ  `ollama_model_name` tagï¼ˆå¦‚ `llama2:7b`ï¼‰
- [ ] ç¢ºä¿ tag å€¼èˆ‡ `inference.yaml` ä¸­çš„ filter ä¸€è‡´

## ğŸ”— ç›¸é—œæ–‡æª”

- **[INFERENCE_TASK_TYPES.md](./INFERENCE_TASK_TYPES.md)** - å®Œæ•´èªªæ˜
- **[OLLAMA_FIX_SUMMARY.md](./OLLAMA_FIX_SUMMARY.md)** - Ollama ä¿®å¾©
- **[inference.yaml](../src/core/configs/inference.yaml)** - Core é…ç½®

## âš¡ å¿«é€Ÿæ¸¬è©¦

```bash
# æ¸¬è©¦ Ollama
curl -X POST http://localhost:8000/inference/infer \
  -H "Content-Type: application/json" \
  -d '{
    "task": "text-generation-ollama",
    "engine": "ollama",
    "model_name": "llama2-7b-chat",
    "data": {"inputs": "ä½ å¥½"},
    "options": {"max_length": 50}
  }'

# æ¸¬è©¦ HuggingFace
curl -X POST http://localhost:8000/inference/infer \
  -H "Content-Type: application/json" \
  -d '{
    "task": "text-generation-hf",
    "engine": "transformers",
    "model_name": "gpt2",
    "data": {"inputs": "AI"},
    "options": {"max_length": 50}
  }'
```

## ğŸ’¡ æœ€ä½³å¯¦è¸

1. âœ… **æ¨è–¦**ï¼šä½¿ç”¨ç´°åˆ†çš„ä»»å‹™é¡å‹ï¼ˆå¦‚ `text-generation-ollama`ï¼‰
2. âœ… **MLflow**: ç¢ºä¿ tags èˆ‡é…ç½®æ–‡ä»¶ä¸€è‡´
3. âœ… **å‘½å**: éµå¾ª `-ollama` æˆ– `-hf` å¾Œç¶´è¦å‰‡
4. âš ï¸ **é¿å…**ï¼šæ··ç”¨å¼•æ“å’Œä»»å‹™é¡å‹ï¼ˆå¦‚ ollama å¼•æ“ç”¨ `-hf` ä»»å‹™ï¼‰
